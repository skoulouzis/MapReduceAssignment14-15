\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
% \usepackage{url}
\usepackage{breakurl} 
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage{mathtools}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{ %
  language=Java,  
  basicstyle=\footnotesize,  
  backgroundcolor=\color{white}, 
  showspaces=false,  
  showstringspaces=false, 
  showtabs=false,  
  frame=single,   
  rulecolor=\color{black}, 
  tabsize=2,   
  captionpos=b,  
  breaklines=true,  
  title=\lstname,  
  keywordstyle=\color{blue}, 
  commentstyle=\color{dkgreen}, 
  stringstyle=\color{mauve}, 
  escapeinside={\%*}{*)},  
  morekeywords={*,...} 
}

\def \year {2016}

\date{}


\title{Hadoop Assignment\\
  University of Amsterdam BSc Informatica
  Concurrency \& Parallel Programming
}


\begin{document}
  \maketitle
  
  \tableofcontents
  
  \section{Overview}
  
  In this assignment, you have to analyze a dataset containing Twitter posts. In particular, you have to
  perform three tasks:
  
  \begin{enumerate}
    \item Find the top ten most popular hashtags
    \item Perform sentiment analysis on the English-language tweets, and nd the average and standard deviation of the sentiments for each of those top ten hashtags
    \item Investigate retweet and reply behaviour
  \end{enumerate}
  
  There is a small dataset (5k tweets) available on Blackboard. We also have larger datasets available in \texttt{/projects/cpp\year} on the cluster. Using them for your experiments is optional, but you might find them useful. Remember, though: the cluster is a shared resource. Don't run large numbers of unnecessary experiments!
  
  For several parts of the assignment, you'll have to make your own decisions about what to do for example, which characters you will accept as part of hash tags, and how you will detect identical retweets. Justify your decisions in your report! 
  
  
  \section{Implementation}
  You should already have the framework from the tutorial; you should simply build on top of it, and implement these analysis tasks using MapReduce with Hadoop. 
  
  Remember: first, develop your code locally, and make sure it works there, and then make sure it works on the cluster, where you should run your experiments for the report.
  
  
  \section{Tag Counter}
  
  First, you have to find the top ten tags in the dataset. You should do the following: 
  
  \begin{enumerate}
    \item Work out how to provide entire tweets (including all the associated information) as input to your mapper. Take a look at the format of the example dataset file, and think about what should you set as the \texttt{textinputformat.record.delimiter} configuration option, to make MapReduce split up the input appropriately 
    
    \item In your Mapper class, extract the text of each tweet, and detect if a line contains any hash tags
    
    \item If the line contains one or more hash tags, emit them to the reducers using the appropriate keys/values
    
    \item In your Reducer class, count the number of hash tags
    
    \item Afterwards, examine the final output, and determine which hash tags are the most popular. \textbf{ Attention:} You shouldn't implement anything else in MapReduce (e.g. a sorting algorithm) to get the top ten tags. You can simply write a script or some code which reads the output files, after you downloaded the results. (Why don't you have to merge the output les for this?). 
  \end{enumerate}
  
  When you're done, it might be a good idea to make a copy of your code, before you move onto the next task.
  
  
  \subsection{Sentiment Analysis}
  For the second part of the assignment, you will need to further modify both the \texttt{Mapper} and \texttt{Reduce} classes.
  
  In natural language processing, language identification is the problem of determining which natural language is used in a text, while sentiment analysis aims to determine the attitude of a person according the her/his writings. 
  
  
  To perform language detection you will use the JLangDetect API (\url{https://github.com/melix/jlangdetect}). Import in you class the UberLanguageDetector package: 
  
  \lstset{language=Java}  
  \begin{lstlisting}
    import me.champeau.ld.UberLanguageDetector;
  \end{lstlisting}
  
  To detect the language of a String variable named \texttt{text} you can use: 
  
  \begin{lstlisting}
    String lang = UberLanguageDetector.getInstance().detectLang(text);
  \end{lstlisting}
  
  If the language in the variable \texttt{text} is in English the \texttt{lang} variable will be set to \texttt{'en'}. 
  
  To perform sentiment analysis on English text you will use the Stanford Natural Language Processing API (\url{http://nlp.stanford.edu/}). To use this API you'll need to import the necessary packages in you class: 
  
  \begin{lstlisting}
    import edu.stanford.nlp.ling.CoreAnnotations;
    import edu.stanford.nlp.pipeline.Annotation;
    import edu.stanford.nlp.pipeline.StanfordCoreNLP;
    import edu.stanford.nlp.rnn.RNNCoreAnnotations;
    import edu.stanford.nlp.sentiment.SentimentCoreAnnotations;
    import edu.stanford.nlp.trees.Tree;
    import edu.stanford.nlp.util.CoreMap;
  \end{lstlisting}
  
  To detect the sentiment of a String variable named \texttt{text} you can use the following method:
  \begin{lstlisting}
    private int findSentiment(String text) {
      Properties props = new Properties();
      props.setProperty("annotators", "tokenize, ssplit, parse, sentiment");
      props.put("parse.model", parseModelPath);
      props.put("sentiment.model", sentimentModelPath);
      StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
      
      int mainSentiment = 0;
      if (text != null && text.length() > 0) {
	int longest = 0;
	Annotation annotation = pipeline.process(text);
	for (CoreMap sentence : annotation
	.get(CoreAnnotations.SentencesAnnotation.class)) {
	  Tree tree = sentence
	  .get(SentimentCoreAnnotations.AnnotatedTree.class);
	  int sentiment = RNNCoreAnnotations.getPredictedClass(tree);
	  String partText = sentence.toString();
	  if (partText.length() > longest) {
	    mainSentiment = sentiment;
	    longest = partText.length();
	  }
	  
	}
      }
      
      //This method is very demanding so try so save some memory 
      pipeline = null;
      System.gc();
      return mainSentiment;
    }
  \end{lstlisting}
  
  
  This method returns an integer that reflects the sentiment of a text. The higher the number the more positive the sentiment of the text.
  
  \textbf{Hint:} Loading the models is very slow.  You can dramatically improve the performance of this function by creating the pipeline in the class constructor instead. 
  
  It might be helpful to know that the standard deviation can be iteratively (value-by-value) calculated
  like this, after you've already calculated the average (mean):
  
  \begin{lstlisting}
    sd = sd + Math.pow(val - mean, 2);
  \end{lstlisting}
  
  
  Importantly, in this method, you need to specify the \texttt{parseModelPath} and \texttt{sentimentModelPath} variables. The first variable gives the path to the \texttt{englishPCFG.ser.gz} file, which is used to perform parsing of English-language text.  The second gives the path to the \texttt{sentiment.ser.gz} file, used for sentiment detection. 
  
  For local testing/use, you can simply download these files from Blackboard. However, on the cluster, you'll need to make sure that the files are available to all the mappers. We've already put them on the HDFS, in \texttt{/projects/cpp\year}.
  
  To make them available, you have to use the \texttt{DistributedCache}, which is provided by the MapReduce framework to cache files (text, archives, etc) needed by applications. To use it, you have to add the files you need to the cache before running your job: 
  
  \begin{lstlisting}
    job.addCacheFile(new URI("/projects/cpp2016/sentiment.ser.gz"));
  \end{lstlisting}
  
  
  Of course, you'll need to import the URI class too. Once you've done that, the files you've cached will be available in the directory which your mapper runs in (so you can just open them by their filename). 
  
  This path doesn't exist on your own computer, so to make this work properly on both your own machine and the cluster, you'll need to check whether your code is running locally, or on the cluster using MapReduce 2.0 (yarn). You can obtain the framework you're running under by checking the value of the \texttt{mapreduce.framework.name} configuration option, which will be \texttt{yarn} when running on the cluster, or \texttt{local} if running locally:
  
  
  \begin{lstlisting}
    if (conf.get("mapreduce.framework.name").equals("yarn"))
  \end{lstlisting}
  
  Therefore, the steps you'll need to take to complete this assignment are: 
  
  \begin{enumerate}
    \item Add the \texttt{englishPCFG.ser.gz} and \texttt{sentiment.ser.gz} files to the list of cached files
    \item Use the mappers to detect if a tweet contains any hash tags, and if it does, detect the language of the tweet
    \item If the language is English perform the sentiment analysis and emit the proper keys and values to the reducers
    \item Finally, use the reducers to calculate the average (mean) sentiment and the standard deviation, for each hash tag
  \end{enumerate}
  
  
  
  \section{Retweets and Replies}
  
  
  For the final part of the assignment, you need to investigate the main two types of engagement on Twitter: retweets, and replies. Remember, the dataset is from 2009, so no metadata is available for this, only the message text. Take a look through the example data, and you should find plenty of examples. 
  
  \textbf{Retweets:} When people retweet (using RT), it usually means they think the content of the tweet is interesting or useful, and so they think their followers would also benefit from seeing it. By retweeting, they say ``take a look'' and expose the tweet to all their followers, giving the tweet a greater reach. 
  
  
  \textbf{Reply:} When a tweet is replied to (using @), it suggests that the tweet has resonated enough with someone that it sparks a conversation, or encourages someone to share it with their followers. You'll find that most ``replies'' aren't actually replies, but just references to another user. We don't expect you to try and distinguish these; you can just assume that they're all replies (if they're not retweets). 
  
  Given the popularity of these two activities, it would be interesting to explore how they are used. You should write code, using MapReduce, which answers the following questions (in approximate order of probable difficulty):
  
  \begin{itemize}
    \item How many tweets are there for each type of reaction (retweets, and replies)?
    \item When do most retweets happen (what times of day), and when do most replies happen? (\textbf{Optional:} Is this different for different languages?
    \item What are the top 10 retweeted messages, and who are they from? 
    \item Who are the top 5 users who are replied to, and which users send the most replies to each of them? 
    \item Who are the top 5 users whose messages are retweeted, and who retweeted each of them the most?
    \item \textbf{Optional:} Are tweets with a certain sentiment more likely to generate more retweets?
    \item \textbf{Optional:} Do those top 10 retweeted messages get significantly more replies? (This one might be quite tricky.)
  \end{itemize}
  
  These are not easy, and you will probably need to implement several di erent mapper/reduce classes. For some of these questions, you might want to run a second MapReduce job, using the output of your first one. For others, you might find it most efficient to use a script or some code on your own computer to calculate the final answer.
  
  You'll probably want to work on a separate copy of your code for this; remember to keep a copy of your code from the other tasks.
  
  Finally: In the provided data sets (especially the smaller ones), you will find that there aren't a unique set of top 5 users, or top 10 messages. You can just pick arbitrarily (or use a slightly different number, if you'd prefer). Just show that you've implemented something which can answer the question, and explain why!
  
  
  \section{Report} \label{sec:report}
  
  You are required to hand in both a report and your code:
  \begin{enumerate}
    \item Your source code, for all of the three tasks. You can hand in one version of the code for each task, or (ideally) one single piece of code that implements all three parts of the analysis. Please only hand in the \textit{source code}. We don't want your \texttt{target} folder or your output files, but your source code which \textbf{must} be complete, including any scripts you may have written/used
    
    \item A short report, of no more than 3 pages
  \end{enumerate}
  
  Your source code should be comprehensively commented, so that we can understand exactly what you're doing. Assume that we already know how MapReduce works, but you should still explain how your code interacts with MapReduce in general. 
  
  
  Your report should contain the following sections:
  
  \begin{enumerate}
    \item Introduction: Very briefly (no more that 2 paragraphs) describe the major components of Hadoop
    \item Implementation: Describe your approach for implementing each part of the Twitter dataset analysis, from a high-level point of view
    
    \item Results: 
    \begin{enumerate}
      \item A table with the top ten hash tags you found, their occurrences, their average sentiment and their standard deviation
      \item A graph showing speedup measurements when using 1, 2, 4, 8 mappers for at least the sentiment analysis task 
      \item Tables or graphs which present your answers to the questions about retweets and replies
    \end{enumerate}
    \item Conclusion: 
    \begin{enumerate}
      \item Discuss your results!
      \item Make sure to talk about the benefit, if any, of adding more mappers. (If you didn't observe any speed up by adding more mappers, explain why!)
      \item Explain what parts of this problem you think are well-suited to Hadoop/MapReduce, and which (if any) are not
    \end{enumerate}
    
  \end{enumerate}
  
  
  \section{Experiments}
  
  Since you are sharing the cluster, it is possible that your measurements may be influenced by other activities.  With this in mind, when you measure speedup, you should be sure to perform multiple experiments, and present your findings in a statistically-sound manner. Be sure to graph the speedup using error bars. Remember, you can calculate speedup (the relative performance improvement when executing a task) using:
  
  \[
  S_p = \frac{T_1}{T_p}
  \]
  
  Where $T_1$ is the execution time when using one node, in this case one mapper and $T_p$ is the execution time when using $p$ nodes, in this case 1,2,4 or 8 mappers.
  
  
  \section{Grading}
  Deadline: See Blackboard. Remember, you have to hand in all your scripts with your code, so you must have already made sure you can run all the experiments you need. 
  
  Grading: Tag Counter: 4/10, Sentiment Analysis: 3/10, Retweets and Replies: 3/10. 
  
  To obtain full points, your code must work correctly, be well-commented and tidy, and produce correct results.  In your report, you will have to include all the requested graphs and results, and provide everything requested in Section \ref{sec:report}.
  
\end{document}  